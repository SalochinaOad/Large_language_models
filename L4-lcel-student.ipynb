{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc925562",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL)\n",
    "* LCEL is ideal when you want to build and orchestrate multi-step workflows for LLM applications in a clear and maintainable way.\n",
    "```\n",
    "      Prompt + Model + Output Parsing (Simple Chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3237808",
   "metadata": {},
   "source": [
    "Option 1: Direct OpenAI SDK\n",
    "* Official OpenAI SDK, typically used when you're not using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai as OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044db1b7-c18c-45d2-be7a-29f027c901e2",
   "metadata": {
    "height": 130,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model= \"gpt-3.5-turbo\",\n",
    "    messages= [{'role': \"user\", \"content\": \"Tell me a joke about Monkey\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a5a15f",
   "metadata": {},
   "source": [
    "Option 2: LangChain Wrapper (ChatOpenAI())\n",
    "* Use this only if you're working within the LangChain framework, which abstracts models, prompts, memory, chains, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f918c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall langchain langchain-core\n",
    "##!pip install \"pydantic>=2.7.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea6227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c432b-b2c9-497b-9912-c9ca4c1e3740",
   "metadata": {},
   "source": [
    "## Simple Chain using Invoke Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aee69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "output_parser= StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e942aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain= prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"topic\": \"monkey\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba33b5-2ae9-44d7-b023-18c903af571a",
   "metadata": {},
   "source": [
    "## More complex chain\n",
    "\n",
    "RunnableMap is like a pre-processor step in a LangChain pipeline.\n",
    "\n",
    "It maps the inputs into the format that the next block (prompt) expects.\n",
    "In this case, you’re preparing a dictionary:\n",
    "\n",
    "``` \n",
    "{\"context\": [...relevant docs...], \"question\": \"your original question\"} \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0199331",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"Practice makes perfect\", \"think before you speak\"],\n",
    "        embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever= vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df87934-1697-405c-b460-5e9bfd16c792",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\"what makes perfect?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871cb26b-97b3-4f63-8bb3-523d3e6d117b",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "retriever.get_relevant_documents(\"what to do before speaking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a7fb6-5821-4934-ab56-9e3300516c05",
   "metadata": {
    "height": 130
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec01c56-731c-4e4f-a5f6-493fba953db0",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc0b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain= RunnableMap({ \"context\" : lambda x: retriever.get_relevant_documents(x['question']),\n",
    "             \"question\" : lambda x: x['question']}) | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8023d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"what makes perfect?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec59c3b-33e7-437f-9b8b-b4652bc3b863",
   "metadata": {},
   "source": [
    "## Bind Method\n",
    "\n",
    "bind() is used to create a new instance of the model with certain parameters fixed.\n",
    "\n",
    "Think of it like \"attaching\" or \"locking in\" a configuration (e.g., function calling schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3efed3b-6d4c-42a4-9692-0cc4596f530b",
   "metadata": {
    "height": 300
   },
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\"type\": \"object\",\"properties\": {\"airport_code\": {\"type\": \"string\",\n",
    "                    \"description\": \"The airport code to get the weather for\"},},\"required\": [\"airport_code\"]}\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions[0]['parameters']['properties']['airport_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02135373",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "model = ChatOpenAI(temperature = 0).bind(functions= functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b095d-9934-41b8-a794-a9dd57e9c733",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a638efeb-b5ce-4aa4-8377-3e86597a03ab",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "runnable.invoke({\"input\": \"what is the weather in sf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22faf5-ea24-48d2-b028-03733b548225",
   "metadata": {
    "height": 538
   },
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    },\n",
    "        {\n",
    "      \"name\": \"sports_search\",\n",
    "      \"description\": \"Search for news of recent sport events\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"team_name\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The sports team to search for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"team_name\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43b030-459f-47e8-a27d-96c2d70cdfef",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "model = model.bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff03e0d-d6c6-4b47-815e-d7ea5b248567",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03855fa3-5e2f-4ab2-aba0-c2cd5423239e",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "runnable.invoke({\"input\": \"how did the patriots do yesterday?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc0c55-48c2-4105-90ec-7297553b8e6a",
   "metadata": {},
   "source": [
    "## Fallbacks\n",
    "* Fallbacks increase robustness if one model/pipeline fails to return usable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b1ea2-7aef-4449-a553-426cb8c5aa30",
   "metadata": {
    "height": 46
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df432efe-9415-42e3-ab57-ecf4d439f369",
   "metadata": {
    "height": 114
   },
   "outputs": [],
   "source": [
    "simple_model = ChatOpenAI(\n",
    "    temperature = 0, \n",
    "    max_tokens=1000, \n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "simple_chain = simple_model | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441928c5-8712-45c5-bfdf-6f51634198a7",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "challenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739e85f-8497-4471-8ec9-17e958d80771",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "simple_model.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20d15c-dc8a-4b6d-a423-a5f814425219",
   "metadata": {},
   "source": [
    "<p style=\\\"background-color:#F5C780; padding:15px\\\"><b>Note:</b> The next line is expected to fail.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e8492-0927-4a3a-b939-947826246330",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "simple_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6814143b-4a35-4d29-bd32-ba461274bcbf",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)\n",
    "chain = model | StrOutputParser() | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f55f04cf-0217-4106-b41f-0e0661d12c27",
   "metadata": {
    "height": 29
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Rose',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'A rose by any other name would smell as sweet'},\n",
       " 'poem2': {'title': 'The Road Not Taken',\n",
       "  'author': 'Robert Frost',\n",
       "  'firstLine': 'Two roads diverged in a yellow wood'},\n",
       " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'Hope is the thing with feathers that perches in the soul'}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5d3f035-b18d-4cba-854d-a43ef8554e48",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "final_chain = simple_chain.with_fallbacks([chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a09fe6a-548c-412d-9468-9efe2b49f7c9",
   "metadata": {
    "height": 29
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Rose',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'A rose by any other name would smell as sweet'},\n",
       " 'poem2': {'title': 'The Road Not Taken',\n",
       "  'author': 'Robert Frost',\n",
       "  'firstLine': 'Two roads diverged in a yellow wood'},\n",
       " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'Hope is the thing with feathers that perches in the soul'}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcfdda0-3db2-4073-a647-f2d62c460349",
   "metadata": {},
   "source": [
    "## Interface\n",
    "In LangChain (or other similar frameworks), the .invoke, .batch, and .stream methods are used to interact with chains or models in different ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b3b27f-b5a0-4db5-a1b0-20754437a47e",
   "metadata": {
    "height": 131
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a short joke about {topic}\"\n",
    ")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c8cabf-ea55-4448-b070-3ec22942c559",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "chain.invoke({\"topic\": \"bears\"}) # a single input to the chain or model and returns the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc58bdb4-a896-46ba-90c4-1b333245229a",
   "metadata": {
    "height": 45
   },
   "outputs": [],
   "source": [
    "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"frogs\"}]) ## Sends a list of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a069d61-0a67-4368-b7c4-367262267bb8",
   "metadata": {
    "height": 46
   },
   "outputs": [],
   "source": [
    "for t in chain.stream({\"topic\": \"bears\"}): \n",
    "    print(t)  # Good for UIs or applications where partial results are needed in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2315b43f-c7e1-4f7b-9595-4cabdc019dea",
   "metadata": {
    "height": 62
   },
   "outputs": [],
   "source": [
    "response = await chain.ainvoke({\"topic\": \"bears\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34841733",
   "metadata": {},
   "source": [
    "# RAG (Retrieval-Augmented Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3082379-f75e-4a74-bee5-c18ddc5ac4dc",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.schema.runnable import RunnableMap\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.retrievers import WikipediaRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "052a6a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\oadsa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wikipedia) (4.13.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\oadsa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from wikipedia) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\oadsa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\oadsa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\oadsa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\oadsa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.8.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\oadsa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4->wikipedia) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\oadsa\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4->wikipedia) (4.14.1)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (pyproject.toml): started\n",
      "  Building wheel for wikipedia (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11785 sha256=df4b127df26109d7c8f46b74d03cf36b5fb3d0147b14dd4d76ece4b10a486616\n",
      "  Stored in directory: c:\\users\\oadsa\\appdata\\local\\pip\\cache\\wheels\\8f\\ab\\cb\\45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\oadsa\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c816827-e5b7-480a-826b-0ca715faca3c",
   "metadata": {
    "height": 29
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'LangChain is one of the generative AI frameworks that Milvus can integrate with for monitoring and alerts.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.schema.runnable import RunnableMap\n",
    "from langchain.retrievers import WikipediaRetriever\n",
    "\n",
    "# First Define response schema\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"answer\", description=\"Answer to the user's question\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# Second step Get format instructions\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# Third step Create Prompt with instructions\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You must answer the question using the context provided.\n",
    "\n",
    "Return your answer as a JSON object with this format:\n",
    "{format_instructions}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\")\n",
    "final_prompt = prompt.partial(format_instructions=format_instructions)\n",
    "\n",
    "# Fourth step DevelofModel and retriever\n",
    "model = ChatOpenAI(temperature=0)\n",
    "retriever = WikipediaRetriever()\n",
    "\n",
    "# Finally create Chain using runnablemap\n",
    "chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "        \"question\": lambda x: x[\"question\"]\n",
    "    })\n",
    "    | final_prompt\n",
    "    | model\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "# Run it\n",
    "result = chain.invoke({\"question\": \"What is LangChain?\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d2d23",
   "metadata": {},
   "source": [
    "```\n",
    "This LangChain pipeline uses a WikipediaRetriever to fetch context based on a user’s question and then generates a structured JSON answer using a prompt template and ChatOpenAI. The StructuredOutputParser enforces a specific output format defined by a response schema.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e6d608-c205-4141-bab8-0304dd910978",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc490d-090d-4e1c-b8ee-bf40ec4da4c3",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe48ff0-fd84-4c9e-8069-02117d57f7f0",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
